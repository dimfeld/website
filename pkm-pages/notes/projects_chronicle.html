---
title: "Chronicle"
tags: Projects
date: 2024-03-29
updated: 2024-04-27
---


  <ul class="list-bullet">
    <li>Provides a proxy which can be called instead of the normal URL, then passes a request to the LLM provider and returns the response. Chronicle can be embedded directly into a Rust application or can run as a standalone server.</li>
    <li><h2>Task List</h2>
      <ul class="list-bullet">
        <li><h3>Up Next</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled  /> Support tool use fields</li>
          </ul>        </li>
        <li><h3>Soon</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled  /> Javascript client
              <ul class="list-bullet">
                <li>This should be both a normal client and have the ability to wrap other common clients such as the OpenAI SDK</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Python client
              <ul class="list-bullet">
                <li>This should be both a normal client and have the ability to wrap other common clients such as the OpenAI SDK</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Easy way to set up clients from JS and Python to call the proxy with appropriate headers
              <ul class="list-bullet">
                <li>This is most useful in concert with other libraries that make LLM calls, like dspy and instructor</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Extra providers
              <ul class="list-bullet">
                <li>Fireworks</li>
                <li>Together</li>
              </ul>            </li>
          </ul>        </li>
        <li><h3>Later/Maybe</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled  /> Send logged data to arbitrary HTTP endpoint
              <ul class="list-bullet">
                <li>This should be done in a way that it can sent to something like Elasticsearch without custom code</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Global rate limiting</li>
            <li><input type="checkbox" disabled  /> When looping around providers with retries, omit providers who had an unrecoverable error.</li>
            <li>Analysis
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> visualize by arbitrary metadata</li>
                <li><input type="checkbox" disabled  /> Ability to create database indexes on arbitrary metadata even in JSON fields</li>
              </ul>            </li>
            <li>Price Tracking
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Associate each provider and its calls with a pricing plan</li>
                <li><input type="checkbox" disabled  /> Fetch and update prices for each provider</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Support binary upload APIs like Deepgram as well</li>
            <li><input type="checkbox" disabled  /> Support streaming responses</li>
            <li><input type="checkbox" disabled  /> Submit request metadata (org/user/workflow id) via HTTP headers or cookies?</li>
          </ul>        </li>
        <li><h3>Done</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled checked /> API should have default to do everything without authorization
              <ul class="list-bullet">
                <li>Do this by not only setting up a default user, but also adding it as the anonymous fallback</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Testing &mdash; Apr 26th, 2024</li>
            <li><input type="checkbox" disabled checked /> For API mode, add data tables as <a href="/notes/projects_filigree">Filigree</a> models instead of using the built-in tables</li>
            <li><input type="checkbox" disabled checked /> When multiple providers are in use, keep retrying even on normally un-retryable errors</li>
            <li><input type="checkbox" disabled checked /> Allow configuring fallback provider and model on retry. &mdash; Apr 24th, 2024
              <ul class="list-bullet">
                <li>This is part of the model alias configuration. Basically instead of a single provider and model there&#39;s an array of provider/model/apikey tuples</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Support model/provider aliases &mdash; Apr 23rd, 2024</li>
            <li><input type="checkbox" disabled checked /> Support api keys &mdash; Apr 23rd, 2024
              <ul class="list-bullet">
                <li>These can only be referenced by aliases</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Save metadata into SQLite or Postgres &mdash; Apr 22nd, 2024</li>
            <li><input type="checkbox" disabled checked /> Load model and provider definitions from a configuration file &mdash; Apr 22nd, 2024</li>
            <li><input type="checkbox" disabled checked /> Store and load model and provider definitions from the database &mdash; Apr 22nd, 2024</li>
            <li><input type="checkbox" disabled checked /> Configurable user agent for HTTP client &mdash; Apr 21st, 2024</li>
            <li><input type="checkbox" disabled checked /> Link requests to internal users/orgs/projects &mdash; Apr 21st, 2024</li>
            <li><input type="checkbox" disabled checked /> Configurable timeout &mdash; Apr 20th, 2024</li>
            <li><input type="checkbox" disabled checked /> Common format chat messages and responses &mdash; Apr 19th, 2024</li>
            <li><input type="checkbox" disabled checked /> Automatic retry with rate-limit support &mdash; Apr 19th, 2023</li>
            <li><input type="checkbox" disabled checked /> Endpoint that proxies the call &mdash; Apr 19th, 2024</li>
            <li><input type="checkbox" disabled checked /> Send all relevant metadata as Otel traces &mdash; Apr 19th, 2024</li>
          </ul>        </li>
      </ul>    </li>
    <li>Probably take some code from Promptbox and change that to use this as a library, since it already has some of the needed functionality</li>
    <li>Maintain a price sheet with input/output token price per provider and model
      <ul class="list-bullet">
        <li>Each price sheet entry as an active flag</li>
        <li>When prices are updated for a model, add a new entry and mark it active</li>
        <li>In the future have a scraper or other mechanism of getting latest price data for each model</li>
      </ul>    </li>
    <li>Support multiple methods of output:
      <ul class="list-bullet">
        <li>Record in a postgres table</li>
        <li>Output OpenTelemetry</li>
      </ul>    </li>
    <li>Consider allowing metadata such as org and user ID can be sent in a cookie or in HTTP headers in addition to the body. Not sure how useful this is though.</li>
    <li>For each entry, record:
      <ul class="list-bullet">
        <li>Org ID</li>
        <li>User ID</li>
        <li>Run ID (ID linking related prompt calls together)</li>
        <li>Workflow Name</li>
        <li>Workflow Step</li>
        <li>Arbitrary other metadata</li>
        <li>endpoint called</li>
        <li>provider and model used</li>
        <li>input text</li>
        <li>output text</li>
        <li>input token count</li>
        <li>output token count</li>
        <li>which price sheet row was used</li>
        <li>response time</li>
      </ul>    </li>
  </ul>

