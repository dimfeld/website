---
title: "Chronicle"
tags: Projects
date: 2024-03-29
updated: 2024-07-27
---


  <ul class="list-bullet">
    <li>Provides a proxy which can be called instead of the normal URL, then passes a request to the LLM provider and returns the response. Chronicle can be embedded directly into a Rust application or can run as a standalone server.</li>
    <li><h2>Task List</h2>
      <ul class="list-bullet">
        <li><h3>Up Next</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled  /> Write documentation</li>
            <li><input type="checkbox" disabled  /> Basic UI for visualizing runs, steps, etc.</li>
            <li><input type="checkbox" disabled  /> Option to skip logging model messages</li>
          </ul>        </li>
        <li><h3>Soon</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled  /> Support tools with Ollama</li>
            <li><input type="checkbox" disabled  /> Python client
              <ul class="list-bullet">
                <li>This should be both a normal client and have the ability to wrap other common clients such as the OpenAI SDK. Needs to be compatible with tools like instructor, DSPy, etc.</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Add fixture tests for Fireworks</li>
            <li><input type="checkbox" disabled  /> Add fixture tests for Together</li>
            <li><input type="checkbox" disabled  /> Add fixture tests for Ollama</li>
            <li><input type="checkbox" disabled  /> Add fixture tests for Anyscale</li>
            <li><input type="checkbox" disabled  /> Add fixture tests for DeepInfra</li>
          </ul>        </li>
        <li><h3>Later/Maybe</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled  /> Function to validate configuration and return a list of errors</li>
            <li>API Management
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Endpoints to manage aliases</li>
                <li><input type="checkbox" disabled  /> Endpoints to manage API keys</li>
              </ul>            </li>
            <li><input type="checkbox" disabled  /> Watch and reload config file</li>
            <li>Request Management
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Allow passing through user-agent header</li>
                <li><input type="checkbox" disabled  /> Simple Request caching
                  <ul class="list-bullet">
                    <li>Cache responses based on provider/model/messages</li>
                    <li>Support in-memory, disk, database, Redis</li>
                  </ul>                </li>
                <li><input type="checkbox" disabled  /> Fetch secrets from AWS secrets store</li>
                <li><input type="checkbox" disabled  /> When looping around providers with retries, omit providers who had an unrecoverable error.</li>
                <li><input type="checkbox" disabled  /> Option for provider-level or model-level rate limiting
                  <ul class="list-bullet">
                    <li>So that new requests coming in will automatically wait or fallback</li>
                  </ul>                </li>
                <li><input type="checkbox" disabled  /> Monitor error rates from providers and auto-switch
                  <ul class="list-bullet">
                    <li>This can be built into the alias system perhaps</li>
                  </ul>                </li>
              </ul>            </li>
            <li>New Providers
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> New Provider: Cohere
                  <ul class="list-bullet">
                    <li>Very different API than the others, it’s different enough from a feature perspective that I’m not sure it’s worth translating between request formats.</li>
                  </ul>                </li>
                <li><input type="checkbox" disabled  /> New Provider: OpenRouter</li>
                <li><input type="checkbox" disabled  /> New Provider: Google Gemini</li>
                <li><input type="checkbox" disabled  /> OctoAI</li>
                <li><input type="checkbox" disabled  /> <a href="https://lepton.ai">Lepton</a></li>
              </ul>            </li>
            <li>Specific Provider Upgrades
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Claude: support &quot;is_error&quot; flag in tool results</li>
                <li><input type="checkbox" disabled  /> Claude: support images in tool results</li>
              </ul>            </li>
            <li>Other Modalities
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Support binary upload APIs like Deepgram as well</li>
              </ul>            </li>
            <li>Logging
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Send logged data to arbitrary HTTP endpoint
                  <ul class="list-bullet">
                    <li>This should be done in a way that it can sent to something like Kafka, Elasticsearch, or Clickhouse using only the configuration, no custom code</li>
                  </ul>                </li>
                <li><input type="checkbox" disabled  /> Send logged data to S3
                  <ul class="list-bullet">
                    <li>As JSON files? As Parquet?</li>
                  </ul>                </li>
                <li><input type="checkbox" disabled  /> Figure out what to do about large data
                  <ul class="list-bullet">
                    <li>saving input and outputs is useful but can start taking up a lot of space. Ideally we can have something that places records in cloud storage, just need to figure out the formats and so on and if/how to make things queryable before they land in storage.</li>
                  </ul>                </li>
              </ul>            </li>
            <li>Analysis
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> visualize by arbitrary metadata</li>
                <li><input type="checkbox" disabled  /> Ability to create database indexes on arbitrary metadata even in JSON fields</li>
              </ul>            </li>
            <li>Price Tracking
              <ul class="list-bullet">
                <li><input type="checkbox" disabled  /> Associate each provider and its calls with a pricing plan</li>
                <li><input type="checkbox" disabled  /> Fetch and update prices for each provider</li>
              </ul>            </li>
          </ul>        </li>
        <li><h3>Done</h3>
          <ul class="list-bullet">
            <li><input type="checkbox" disabled checked /> New Provider: AWS Bedrock &mdash; Jul 8th, 2024
              <ul class="list-bullet">
                <li><a href="https://lib.rs/crates/aws-sdk-bedrockruntime">https://lib.rs/crates/aws-sdk-bedrockruntime</a></li>
                <li><a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Operations_Amazon_Bedrock_Runtime.html">https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Operations_Amazon_Bedrock_Runtime.html</a></li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Run and Step tracing &mdash; Jun 30th, 2024</li>
            <li><input type="checkbox" disabled checked /> Add Mistral support &mdash; Jun 19th, 2024</li>
            <li><input type="checkbox" disabled checked /> Streaming with Groq and Ollama &mdash; Jun 1st, 2024</li>
            <li><input type="checkbox" disabled checked /> Enhance test suite with real-world cases &mdash; May 31st, 2024
              <ul class="list-bullet">
                <li>This uses streaming and non-streaming responses from various provider types, for both regular text and tool calls.</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Streaming with Claude &mdash; May 31st, 2024</li>
            <li><input type="checkbox" disabled checked /> Streaming support &mdash; May 31st, 2024</li>
            <li><input type="checkbox" disabled checked /> &quot;Simple&quot; API can build for Postgres
              <ul class="list-bullet">
                <li>Dropped the &quot;full web app&quot; version of the API. This will come back at some later time</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Anthropic now supports &quot;required&quot; tool mode</li>
            <li><input type="checkbox" disabled checked /> Recover from Groq function calling failure</li>
            <li><input type="checkbox" disabled checked /> Endpoint for generic event logging &mdash; May 8th, 2024
              <ul class="list-bullet">
                <li>Take the same metadata that we use for LLM calls, store them in a different table with just an event type and data json blob.</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Support tool use fields &mdash; May 1st, 2024</li>
            <li><input type="checkbox" disabled checked /> Simpler API server that supports SQLite &mdash; Apr 30th, 2024
              <ul class="list-bullet">
                <li>This will just use the built-in proxy tables, but is better for simpler use since it writes to SQLite</li>
                <li>Autoload config files from the XDG directories</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Javascript client &mdash; Apr 29th, 2024
              <ul class="list-bullet">
                <li>This comes with a Chronicle-specific client, and can also redirect clients such as the OpenAI SDK using a custom fetch function.</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Submit request metadata (org/user/workflow id) via HTTP headers &mdash; Apr 29th, 2024</li>
            <li><input type="checkbox" disabled checked /> API should have default to do everything without authorization
              <ul class="list-bullet">
                <li>Do this by not only setting up a default user, but also adding it as the anonymous fallback</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Testing &mdash; Apr 26th, 2024</li>
            <li><input type="checkbox" disabled checked /> For API mode, add data tables as <a href="/notes/projects_filigree">Filigree</a> models instead of using the built-in tables</li>
            <li><input type="checkbox" disabled checked /> When multiple providers are in use, keep retrying even on normally un-retryable errors</li>
            <li><input type="checkbox" disabled checked /> Allow configuring fallback provider and model on retry. &mdash; Apr 24th, 2024
              <ul class="list-bullet">
                <li>This is part of the model alias configuration. Basically instead of a single provider and model there&#39;s an array of provider/model/apikey tuples</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Support model/provider aliases &mdash; Apr 23rd, 2024</li>
            <li><input type="checkbox" disabled checked /> Support api keys &mdash; Apr 23rd, 2024
              <ul class="list-bullet">
                <li>These can only be referenced by aliases</li>
              </ul>            </li>
            <li><input type="checkbox" disabled checked /> Save metadata into SQLite or Postgres &mdash; Apr 22nd, 2024</li>
            <li><input type="checkbox" disabled checked /> Load model and provider definitions from a configuration file &mdash; Apr 22nd, 2024</li>
            <li><input type="checkbox" disabled checked /> Store and load model and provider definitions from the database &mdash; Apr 22nd, 2024</li>
            <li><input type="checkbox" disabled checked /> Configurable user agent for HTTP client &mdash; Apr 21st, 2024</li>
            <li><input type="checkbox" disabled checked /> Link requests to internal users/orgs/projects &mdash; Apr 21st, 2024</li>
            <li><input type="checkbox" disabled checked /> Configurable timeout &mdash; Apr 20th, 2024</li>
            <li><input type="checkbox" disabled checked /> Common format chat messages and responses &mdash; Apr 19th, 2024</li>
            <li><input type="checkbox" disabled checked /> Automatic retry with rate-limit support &mdash; Apr 19th, 2023</li>
            <li><input type="checkbox" disabled checked /> Endpoint that proxies the call &mdash; Apr 19th, 2024</li>
            <li><input type="checkbox" disabled checked /> Send all relevant metadata as Otel traces &mdash; Apr 19th, 2024</li>
          </ul>        </li>
      </ul>    </li>
    <li>Probably take some code from Promptbox and change that to use this as a library, since it already has some of the needed functionality</li>
    <li>Maintain a price sheet with input/output token price per provider and model
      <ul class="list-bullet">
        <li>Each price sheet entry as an active flag</li>
        <li>When prices are updated for a model, add a new entry and mark it active</li>
        <li>In the future have a scraper or other mechanism of getting latest price data for each model</li>
      </ul>    </li>
    <li>Support multiple methods of output:
      <ul class="list-bullet">
        <li>Record in a postgres table</li>
        <li>Output OpenTelemetry</li>
      </ul>    </li>
    <li>Consider allowing metadata such as org and user ID can be sent in a cookie or in HTTP headers in addition to the body. Not sure how useful this is though.</li>
    <li>For each entry, record:
      <ul class="list-bullet">
        <li>Org ID</li>
        <li>User ID</li>
        <li>Run ID (ID linking related prompt calls together)</li>
        <li>Workflow Name</li>
        <li>Workflow Step</li>
        <li>Arbitrary other metadata</li>
        <li>endpoint called</li>
        <li>provider and model used</li>
        <li>input text</li>
        <li>output text</li>
        <li>input token count</li>
        <li>output token count</li>
        <li>which price sheet row was used</li>
        <li>response time</li>
      </ul>    </li>
  </ul>

